# ğŸ¤– ML Preprocessing Lab

**Suite Avanzado de Preprocesamiento y Entrenamiento para Machine Learning**

Una aplicaciÃ³n profesional de Streamlit que implementa el pipeline completo de preprocesamiento de datos y **entrenamiento automÃ¡tico de modelos de ML** segÃºn los requerimientos de la **Actividad Individual** del curso de Machine Learning.

[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB.svg)](https://python.org)

## ğŸ¯ CaracterÃ­sticas Principales

### ğŸ“Š **Pipeline Completo de 6 Etapas**
1. **ğŸ“¥ Carga del Dataset** - ImportaciÃ³n automÃ¡tica desde archivos CSV
2. **ğŸ” ExploraciÃ³n Inicial** - AnÃ¡lisis estadÃ­stico completo (.info(), .describe(), nulos, tipos)
3. **ğŸ§¹ Limpieza de Datos** - Manejo de nulos, duplicados y outliers
4. **ğŸ”¤ CodificaciÃ³n** - TransformaciÃ³n de variables categÃ³ricas (Label Encoding)
5. **ğŸ“ NormalizaciÃ³n** - EstandarizaciÃ³n con Standard Scaler
6. **âœ‚ï¸ DivisiÃ³n Train/Test** - SeparaciÃ³n estratificada con proporciones exactas

### ğŸ¨ **Interfaz Profesional**
- âœ… **Interfaz personalizada** sin navegaciÃ³n automÃ¡tica
- âœ… **DiseÃ±o responsive** con paleta de colores profesional
- âœ… **Visualizaciones interactivas** en tiempo real
- âœ… **MÃ©tricas en tiempo real** con tarjetas animadas
- âœ… **ExportaciÃ³n mÃºltiple** (CSV, Excel, JSON, Reportes Markdown)
- âœ… **CÃ³digo reutilizable** generado automÃ¡ticamente

### ğŸ“‚ **Datasets Incluidos**
| Dataset | DescripciÃ³n | TamaÃ±o | ProporciÃ³n Train/Test |
|---------|-------------|--------|----------------------|
| **ğŸš¢ Titanic** | PredicciÃ³n de supervivencia | 891 filas | 70% / 30% |
| **ğŸ“ Student Performance** | PredicciÃ³n de calificaciones | 395 filas | 80% / 20% |
| **ğŸŒ¸ Iris** | ClasificaciÃ³n de especies | 150 filas | 70% / 30% |

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos
- **Python 3.8+**
- **pip** (gestor de paquetes)

### InstalaciÃ³n

1. **Clona o descarga el proyecto**
   ```bash
   git clone https://github.com/Jeanfranco06/ml_preprocessing_lab.git
   cd ml_preprocessing_lab
   ```

2. **Instala las dependencias**
   ```bash
   pip install -r requirements.txt
   ```

3. **Ejecuta la aplicaciÃ³n**
   ```bash
   streamlit run app.py
   ```

4. **Abre tu navegador** en `http://localhost:8501`

## ğŸš€ Despliegue en Streamlit Cloud

### Requisitos Previos
- **Cuenta en GitHub** con el repositorio del proyecto
- **Cuenta en Streamlit Cloud** (gratuita)

### Pasos para Desplegar

1. **Sube el cÃ³digo a GitHub**
   ```bash
   git add .
   git commit -m "Ready for deployment"
   git push origin main
   ```

2. **Ve a [Streamlit Cloud](https://share.streamlit.io)**

3. **Conecta tu repositorio**
   - Haz clic en "New app"
   - Selecciona tu repositorio de GitHub
   - Configura:
     - **Repository**: `Jeanfranco06/ml_preprocessing_lab`
     - **Branch**: `main`
     - **Main file path**: `app.py`
     - **Python version**: `3.8` o superior

4. **Haz clic en "Deploy"**

5. **Â¡Tu app estarÃ¡ lista en minutos!**

### Archivos de ConfiguraciÃ³n para Despliegue

El proyecto incluye todos los archivos necesarios para Streamlit Cloud:

- âœ… **`app.py`** - Archivo principal de la aplicaciÃ³n
- âœ… **`requirements.txt`** - Todas las dependencias Python
- âœ… **`packages.txt`** - Dependencias del sistema (si es necesario)
- âœ… **`.streamlit/config.toml`** - ConfiguraciÃ³n de Streamlit
- âœ… **`datasets/`** - Datos incluidos en el repositorio

### SoluciÃ³n de Problemas Comunes

**Error de memoria**: Si la app se queda sin memoria, considera reducir el tamaÃ±o de los datasets o optimizar las visualizaciones.

**Tiempo de carga**: Las primeras cargas pueden ser lentas. Streamlit Cloud optimiza automÃ¡ticamente las cargas posteriores.

**Dependencias faltantes**: AsegÃºrate de que todas las librerÃ­as estÃ©n en `requirements.txt`.

## ğŸ“‹ Uso de la AplicaciÃ³n

### NavegaciÃ³n AutomÃ¡tica
La aplicaciÃ³n utiliza la **navegaciÃ³n automÃ¡tica de Streamlit**. En el menÃº lateral encontrarÃ¡s:

1. **ğŸ  Inicio** - InformaciÃ³n general y resumen del proyecto
2. **ğŸš¢ Titanic** - Pipeline completo para dataset Titanic
3. **ğŸ“ Student Performance** - Pipeline completo para dataset estudiantil
4. **ğŸŒ¸ Iris** - Pipeline completo para dataset Iris

### Flujo de Trabajo TÃ­pico
1. **Selecciona un dataset** del menÃº lateral
2. **Navega por las 6 pestaÃ±as** en orden secuencial
3. **Revisa los resultados** en cada etapa del pipeline
4. **Visualiza las mÃ©tricas** y estadÃ­sticas generadas
5. **Exporta los resultados** en mÃºltiples formatos

## ğŸ—ï¸ Arquitectura del Proyecto

```
ml_preprocessing_lab/
â”œâ”€â”€ ğŸ“‚ config/                        # ConfiguraciÃ³n del sistema
â”‚   â””â”€â”€ settings.yaml                 # ConfiguraciÃ³n en YAML
â”œâ”€â”€ ğŸ“‚ src/                            # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ğŸ“‚ config/                     # Sistema de configuraciÃ³n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config_manager.py          # Gestor de configuraciÃ³n
â”‚   â”œâ”€â”€ ğŸ“‚ utils/                      # Utilidades y helpers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py                  # Sistema de logging
â”‚   â”‚   â””â”€â”€ helpers.py                 # Funciones auxiliares
â”‚   â”œâ”€â”€ ğŸ“‚ data/                       # Manejo de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loaders.py                 # Carga de datasets
â”‚   â”‚   â””â”€â”€ preprocessing.py           # Preprocesamiento
â”‚   â”œâ”€â”€ ğŸ“‚ models/                     # Modelos de ML
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py                 # Entrenamiento de modelos
â”‚   â”‚   â”œâ”€â”€ evaluator.py               # EvaluaciÃ³n de modelos
â”‚   â”‚   â””â”€â”€ comparer.py                # ComparaciÃ³n de modelos
â”‚   â”œâ”€â”€ ğŸ“‚ visualization/              # VisualizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ charts.py                  # GrÃ¡ficos y visualizaciones
â”‚   â”‚   â””â”€â”€ metrics.py                 # MÃ©tricas y KPIs
â”‚   â””â”€â”€ ğŸ“‚ export/                     # ExportaciÃ³n y reportes
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ reports.py                 # GeneraciÃ³n de reportes
â”œâ”€â”€ ğŸ“„ app.py                          # PÃ¡gina principal de Streamlit
â”œâ”€â”€ ğŸ“‚ pages/                          # PÃ¡ginas adicionales de Streamlit
â”‚   â”œâ”€â”€ Titanic.py                     # Pipeline completo Titanic
â”‚   â”œâ”€â”€ Student_Performance.py         # Pipeline Student Performance
â”‚   â””â”€â”€ Iris.py                        # Pipeline Iris
â”œâ”€â”€ ğŸ“‚ datasets/                       # Datos del proyecto
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                        # Datos originales
â”‚   â”‚   â”œâ”€â”€ titanic.csv
â”‚   â”‚   â”œâ”€â”€ student-mat.csv
â”‚   â”‚   â””â”€â”€ iris.csv
â”‚   â””â”€â”€ ğŸ“‚ processed/                  # Datos procesados
â”œâ”€â”€ ğŸ“‚ tests/                          # Tests unitarios
â”œâ”€â”€ ğŸ“‚ logs/                           # Archivos de log
â”œâ”€â”€ ğŸ“‚ .streamlit/                     # ConfiguraciÃ³n de Streamlit
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ ğŸ“‚ assets/                         # Recursos estÃ¡ticos
â”‚   â””â”€â”€ styles.css
â”œâ”€â”€ ğŸ“„ requirements.txt                # Dependencias Python
â”œâ”€â”€ ğŸ“„ .gitignore                      # Archivos ignorados por Git
â”œâ”€â”€ ğŸ“„ README.md                       # DocumentaciÃ³n
â””â”€â”€ ğŸ“„ LICENSE                         # Licencia MIT
```

## ğŸ“Š Requerimientos AcadÃ©micos Cumplidos

### âœ… **Etapas del Pipeline (PDF)**
- âœ… **Carga del dataset** desde archivos CSV
- âœ… **ExploraciÃ³n inicial** (.info(), .describe(), valores nulos, tipos de datos)
- âœ… **Limpieza de datos** (manejo de nulos, eliminaciÃ³n de duplicados, outliers)
- âœ… **CodificaciÃ³n de variables categÃ³ricas** (Label Encoding)
- âœ… **NormalizaciÃ³n/estandarizaciÃ³n** (Standard Scaler)
- âœ… **DivisiÃ³n train/test** (proporciones exactas: 70/30, 80/20, 70/30)
- âœ… **Primeros 5 registros procesados** mostrados en cada dataset

### âœ… **CaracterÃ­sticas TÃ©cnicas**
- âœ… **Interfaz intuitiva** con navegaciÃ³n automÃ¡tica
- âœ… **Visualizaciones claras** de cada etapa
- âœ… **MÃ©tricas detalladas** en tiempo real
- âœ… **ExportaciÃ³n de resultados** en mÃºltiples formatos
- âœ… **CÃ³digo modular** y bien estructurado
- âœ… **DocumentaciÃ³n completa** del proceso

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### **Core**
- **Streamlit 1.28+** - Framework web para aplicaciones de ML
- **Pandas** - ManipulaciÃ³n y anÃ¡lisis de datos
- **NumPy** - ComputaciÃ³n numÃ©rica
- **Scikit-learn** - Algoritmos de ML y preprocesamiento

### **VisualizaciÃ³n**
- **Matplotlib** - GrÃ¡ficos base
- **Seaborn** - Visualizaciones estadÃ­sticas
- **Plotly** - GrÃ¡ficos interactivos

### **ExportaciÃ³n**
- **OpenPyXL** - ExportaciÃ³n a Excel

## ğŸ“ˆ Resultados Esperados

### **Titanic Dataset**
- **Input**: 891 filas Ã— 12 columnas
- **Output**: Dataset limpio con ~800 filas Ã— 9 columnas
- **Train/Test**: 623/268 filas (70%/30%)
- **Variables target**: Supervivencia (0/1)

### **Student Performance Dataset**
- **Input**: 395 filas Ã— 33 columnas
- **Output**: Dataset limpio con ~390 filas Ã— 30 columnas
- **Train/Test**: 316/79 filas (80%/20%)
- **Variables target**: CalificaciÃ³n final G3 (0-20)

### **Iris Dataset**
- **Input**: 150 filas Ã— 6 columnas
- **Output**: Dataset limpio con 150 filas Ã— 5 columnas
- **Train/Test**: 105/45 filas (70%/30%)
- **Variables target**: Especies (setosa, versicolor, virginica)

## ğŸ¤ Contribuciones

Este proyecto estÃ¡ diseÃ±ado para fines educativos. Sugerencias de mejora:

- Agregar mÃ¡s datasets
- Implementar tÃ©cnicas adicionales de preprocesamiento
- Mejorar las visualizaciones
- Agregar mÃ¡s formatos de exportaciÃ³n
- Optimizar el rendimiento

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Ver archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- **Streamlit** por el increÃ­ble framework
- **Scikit-learn** por las utilidades de ML
- **Kaggle** por los datasets
- **Comunidad de ML** por el conocimiento compartido

---
